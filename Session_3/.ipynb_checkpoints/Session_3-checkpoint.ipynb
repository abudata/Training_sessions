{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merging Dataframes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import psycopg2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import pylab as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Connecting to redshift\n",
    "con = psycopg2.connect(\n",
    "host ='gl-analytics-production-1.cfzpbyicru2p.us-east-1.redshift.amazonaws.com',\n",
    "port ='5439',\n",
    "database = 'analysttest',\n",
    "user = 'analysttest',\n",
    "password ='yi3xigh4OoGho4uceire')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing SQL query for daily first connection\n",
    "DailyFC = pd.read_sql_query(\n",
    "\"\"\"\n",
    "SELECT \n",
    "    DISTINCT(account_id) as users,\n",
    "    DATE_TRUNC('day',TIMESTAMP 'epoch' + \"time\" * INTERVAL '1 second ') as timestamp_main\n",
    "FROM \n",
    "    tmnt.daily_first_connection\n",
    "WHERE \n",
    "    DATE_TRUNC('day',TIMESTAMP 'epoch' + \"time\" * INTERVAL '1 second ') BETWEEN '2017-03-01 12:00:01' AND '2017-03-02 23:59:59'\n",
    "\"\"\", con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Writing SQL query for paying users\n",
    "Paying_user = pd.read_sql_query(\n",
    "\"\"\"\n",
    "SELECT \n",
    "    DISTINCT(account_id) as paying_user,\n",
    "    product, \n",
    "    price,\n",
    "    DATE_TRUNC('day',TIMESTAMP 'epoch' + \"time\" * INTERVAL '1 second ') as transaction_time\n",
    "FROM \n",
    "    tmnt.verified_transactions\n",
    "WHERE\n",
    "    DATE_TRUNC('day',TIMESTAMP 'epoch' + \"time\" * INTERVAL '1 second ') BETWEEN '2017-03-01 12:00:01' AND '2017-03-02 23:59:59'\n",
    "\"\"\", con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DailyFC.head();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(DailyFC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Paying_user.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(Paying_user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Closing connection with redshift.\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the list of column names\n",
    "list(Paying_user.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting 'pyaing_user' column to index\n",
    "Paying_user = Paying_user.set_index('paying_user')\n",
    "Paying_user.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(Paying_user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting 'users' to index\n",
    "DailyFC = DailyFC.set_index('users')\n",
    "DailyFC.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(DailyFC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging datasets with each other. \n",
    "pd.merge(DailyFC, Paying_user, how='outer', left_index=True, right_index=True).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(DailyFC, Paying_user, how='inner', left_index=True, right_index=True).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(DailyFC, Paying_user, how='left', left_index=True, right_index=True).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(DailyFC, Paying_user, how='right', left_index=True, right_index=True).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It's important to reset the index \n",
    "DailyFC = DailyFC.reset_index()\n",
    "Paying_user = Paying_user.reset_index()\n",
    "pd.merge(DailyFC, Paying_user, how='left', left_on='users', right_on='paying_user').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Idiomatic Pandas: Making Code Pandorable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "Paying_user.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taking all the price with 9.99.\n",
    "# Removing NA if any\n",
    "# Setting index\n",
    "# Changing the column name\n",
    "\n",
    "(Paying_user.where(Paying_user['price']==9.99)\n",
    "    .dropna()\n",
    "    .set_index(['paying_user','product'])\n",
    "    .rename(columns={'price': 'amount'})).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taking all the price with 9.99.\n",
    "# Removing NA if any\n",
    "# Setting index\n",
    "# Changing the column name\n",
    "# Dropping transaction_Time column\n",
    "\n",
    "(Paying_user.where(Paying_user['price']==9.99)\n",
    "    .dropna()\n",
    "    .drop('transaction_time', axis=1)\n",
    "    .set_index(['paying_user','product'])\n",
    "    .rename(columns={'price': 'amount'})).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How to write it not being pandorable\n",
    "Paying_user = Paying_user[Paying_user['price']==9.99]\n",
    "Paying_user.set_index(['paying_user','product'], inplace=True)\n",
    "Paying_user.rename(columns={'price': 'amount'}).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New dataset (For practicing)\n",
    "import pandas as pd\n",
    "df = pd.read_csv('census.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select SUMLEV==50\n",
    "# Drop all NA\n",
    "# Set_index to STANME and CTYNAME\n",
    "# Rename column ESTIMATESBASE2010 to Estimates Base 2010\n",
    "(df.where(df['SUMLEV']==50)\n",
    "    .dropna()\n",
    "    .set_index(['STNAME', 'CTYNAME'])\n",
    "    .rename(columns={'ESTIMATESBASE2010': 'Estimates Base 2010'})).head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# How to calcuate maximum and minimum of each POPESTIMATE from 2010 to 2015 in each row?\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def max_min(col):\n",
    "    data = col[['POPESTIMATE2010',\n",
    "                'POPESTIMATE2011',\n",
    "                'POPESTIMATE2012',\n",
    "                'POPESTIMATE2013',\n",
    "                'POPESTIMATE2014',\n",
    "                'POPESTIMATE2015']]\n",
    "    return pd.Series({'max':np.max(data), 'min':np.min(data)})\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.apply(max_min, axis=1).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How to calculate min and max of each row and add them as a column\n",
    "import numpy as np\n",
    "def min_max(col):\n",
    "    data = col[['POPESTIMATE2010',\n",
    "                'POPESTIMATE2011',\n",
    "                'POPESTIMATE2012',\n",
    "                'POPESTIMATE2013',\n",
    "                'POPESTIMATE2014',\n",
    "                'POPESTIMATE2015']]\n",
    "    col['max'] = np.max(data)\n",
    "    col['min'] = np.min(data)\n",
    "    return col\n",
    "df.apply(min_max, axis=1).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = ['POPESTIMATE2010',\n",
    "        'POPESTIMATE2011',\n",
    "        'POPESTIMATE2012',\n",
    "        'POPESTIMATE2013',\n",
    "        'POPESTIMATE2014',\n",
    "        'POPESTIMATE2015']\n",
    "df.apply(lambda x: np.max(x[col]), axis=1).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Group by"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.read_csv('census.csv')\n",
    "df = df[df['SUMLEV']==50]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%timeit -n 10\n",
    "# How to calcualte average of population for each STATE based on the number of counties. \n",
    "for state in df['STNAME'].unique():\n",
    "    avg = np.average(df.where(df['STNAME']==state).dropna()['CENSUS2010POP'])\n",
    "    print('Counties in state ' + state + ' have an average population of ' + str(avg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%timeit -n 10\n",
    "# More efficeint way\n",
    "for group, frame in df.groupby('STNAME'):\n",
    "    avg = np.average(frame['CENSUS2010POP'])\n",
    "    print('Counties in state ' + group + ' have an average population of ' + str(avg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading census data again.\n",
    "df = pd.read_csv('census.csv')\n",
    "df = df[df['SUMLEV']==50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How to use groupby?\n",
    "df.groupby('STNAME').agg({'CENSUS2010POP': np.average}).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(df.groupby(level=0)['POPESTIMATE2010','POPESTIMATE2011']))\n",
    "print(type(df.groupby(level=0)['POPESTIMATE2010']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating avg and sum of each STANAME for CENSUS2010POP (Pandorable way)\n",
    "(df.set_index('STNAME').groupby(level=0)['CENSUS2010POP']\n",
    "    .agg({'avg': np.average, 'sum': np.sum})).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df.set_index('STNAME').groupby(level=0)['POPESTIMATE2010','POPESTIMATE2011']\n",
    "    .agg({'avg': np.average, 'sum': np.sum})).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming the col name(Pandorable way)\n",
    "(df.set_index('STNAME').groupby(level=0)['POPESTIMATE2010','POPESTIMATE2011']\n",
    "    .agg({'POPESTIMATE2010': np.average, 'POPESTIMATE2011': np.sum})).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pivot Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#http://open.canada.ca/data/en/dataset/98f1a129-f628-4ce4-b24d-6f16bf24dd64\n",
    "df = pd.read_csv('cars.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing Make column values to the dataset columns\n",
    "df.pivot_table(values='(kW)', index='YEAR', columns='Make', aggfunc=np.mean).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.pivot_table(values='(kW)', index='YEAR', columns='Make', aggfunc=[np.mean, np.min], margins=True).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
